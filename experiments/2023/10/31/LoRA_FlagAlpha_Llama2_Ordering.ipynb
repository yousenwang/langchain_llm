{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1eaf3f5-4903-4cdf-947d-8e00d1bfaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "os.environ['HTTP_PROXY']=\"http://127.0.0.1:8098\"\n",
    "os.environ['HTTPS_PROXY']=\"http://127.0.0.1:8098\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9998a5d-448e-4c5e-a6c7-d3c928cab440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q bitsandbytes datasets accelerate loralib\n",
    "# !pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b1ac39-ed9f-4780-a8a6-f858f065a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e059d3-5877-4f38-8c82-d820dd010c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 81M\n",
      "drwxr-xr-x 10 root root 4.0K Oct 26 13:21 .\n",
      "drwxr-xr-x  5 root root   61 Oct 24 15:26 ..\n",
      "drwxr-xr-x  6 root root   65 Aug 21 09:16 models--bigscience--bloom-1b7\n",
      "drwxr-xr-x  6 root root   65 Oct 24 18:26 models--bigscience--bloom-7b1\n",
      "drwxr-xr-x  6 root root   65 Aug 30 22:52 models--FlagAlpha--Llama2-Chinese-7b-Chat\n",
      "drwxr-xr-x  6 root root   65 Oct 24 11:46 models--meta-llama--Llama-2-7b-chat-hf\n",
      "drwxr-xr-x  6 root root   65 Sep  5 00:14 models--shibing624--text2vec-base-chinese\n",
      "drwxr-xr-x  2 root root    6 Aug 29 13:57 models--TheBloke--Llama-2-7B-GGML\n",
      "drwxr-xr-x  6 root root   65 Oct 26 13:21 models--tiiuae--falcon-7b\n",
      "drwxr-xr-x  5 root root   48 Oct 26 09:36 models--ysw96--my_awesome_peft_model\n",
      "-rw-------  1 root root  80M Oct 26 08:22 tmpd_8zze2t\n",
      "-rw-------  1 root root    0 Oct 24 11:18 tmpxe5e_q0g\n",
      "-rw-r--r--  1 root root    1 Jul 26 16:10 version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /root/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1d2e21-637a-489c-8923-4a07a6b8409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263e80ff-e155-4c7b-8a02-84e060ea7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.35.0.dev0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /usr/local/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft, sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a704a34-6ce4-4acc-bdf4-c2a7ee196e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: peft\n",
      "Version: 0.6.0.dev0\n",
      "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
      "Home-page: https://github.com/huggingface/peft\n",
      "Author: The HuggingFace team\n",
      "Author-email: sourab@huggingface.co\n",
      "License: Apache\n",
      "Location: /usr/local/lib/python3.10/site-packages\n",
      "Requires: accelerate, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3441f3da-8ce7-432d-b52a-c70da2e30462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 30 16:46:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     Off | 00000000:AF:00.0 Off |                    0 |\n",
      "|  0%   28C    P0              68W / 300W |  19484MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     21224      C   /data/python/laby/llama.cpp/server         7538MiB |\n",
      "|    0   N/A  N/A     21227      C   /data/python/laby/llama.cpp/server        11866MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6576eac2-588e-4531-be93-a9d3ebf523b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uqqq pip --progress-bar off\n",
    "# !pip install -qqq bitsandbytes==0.39.0 --progress-bar off\n",
    "# !pip install -qqq torch==2.0.1 --progress-bar off\n",
    "# !pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc --progress-bar off\n",
    "# !pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f --progress-bar off\n",
    "# !pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71 --progress-bar off\n",
    "# !pip install -qqq datasets==2.12.0 --progress-bar off\n",
    "# !pip install -qqq loralib==0.1.1 --progress-bar off\n",
    "# !pip install -qqq einops==0.6.1 --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f48e22-a6ca-4fa9-add2-f317b477c51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 16:46:48.014019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 16:46:48.814501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33dc848-0644-403d-8a1e-43a9f762cdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29aa048-bd6b-4f49-a72e-9b4392026bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569fb1f5-e493-49b8-98d9-43ca40d1ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0fc0c9903349c7ad0bbfdd686a6043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"FlagAlpha/Llama2-Chinese-7b-Chat\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    # trust_remote_code=True,\n",
    "    local_files_only=True,\n",
    "    quantization_config=bnb_config,\n",
    "    # temperature=0.0\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd698a99-1a8c-42a3-975e-e6dd3e195ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 30 16:49:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     Off | 00000000:AF:00.0 Off |                    0 |\n",
      "|  0%   28C    P0              68W / 300W |  23763MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6946      C   /usr/local/bin/python3.10                  4274MiB |\n",
      "|    0   N/A  N/A     21224      C   /data/python/laby/llama.cpp/server         7538MiB |\n",
      "|    0   N/A  N/A     21227      C   /data/python/laby/llama.cpp/server        11866MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40485e1-1212-4db3-be03-7c18d434390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177940a5-dad8-47f6-84ae-551985c2728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 262410240 || all params: 3500412928 || trainable%: 7.496550989769399\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a556439-1c76-4a0b-8a51-b9e20f80c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8c289bd-6ee6-4a2b-8f5c-bac5780c08b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 39976960 || all params: 3540389888 || trainable%: 1.1291682911958425\n"
     ]
    }
   ],
   "source": [
    "# config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"query_key_value\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "# )\n",
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00654b-b1c7-4833-a063-47511050cbcf",
   "metadata": {},
   "source": [
    "## Inference Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281e2469-2c5b-4ddf-9faa-c34d583a0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 权益购买的功能用途是什么？\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    ": 权益购买的功能用途是什么？\n",
    ":\n",
    "\"\"\".strip()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87b4b437-1b57-472e-923b-aec07fe2127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.0\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b26d6bf-e903-4c1a-a17e-c955d6930aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 4096,\n",
       "  \"max_new_tokens\": 200,\n",
       "  \"pad_token_id\": 2,\n",
       "  \"temperature\": 0.0,\n",
       "  \"top_p\": 0.7\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7283b37a-2f4f-4b2c-90c8-cb200021780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 权益购买的功能用途是什么？\n",
      ": 权益购买是一种在互联网上购买权益的方式，通常是指在社交媒体上购买的权益。权益购买的功能用途是为了让用户在社交媒体上获得更多的权益，例如在Facebook上购买的权益可以为用户提供更多的社交功能，例如更多的朋友、更多的粉丝、更多的赞评等。\n",
      "\n",
      "CPU times: user 16.2 s, sys: 379 ms, total: 16.6 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cc0d767-34c0-45c1-b1a4-1dc112f0c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/qa_dataset_cn_ordering.json\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50d2d321-1916-438e-a1d5-13c1be02e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '权益购买的功能用途是什么？',\n",
      " 'answer': '权益购买的功能用途是购买需要的平台版本，确定该账号所持权益，并进行付款和索取发票。这个功能可以让用户根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。同时，用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。'}\n"
     ]
    }
   ],
   "source": [
    "pprint(data[0], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1939600-43c2-4f47-b39a-1a54d1feddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '权益购买的具体操作步骤是什么？',\n",
      " 'answer': '权益购买的具体操作步骤包括登录账号后，点击【平台版本】，进入权益购买界面，【+选择权益】可进行预购版本的选择，点击下一步或者购物车，进行订单的确认和提交。订单提交后重新登录。这些步骤可以让用户方便地选择需要的平台版本，并完成订单的提交。'}\n"
     ]
    }
   ],
   "source": [
    "pprint(data[1], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aba7b21f-663c-4455-a638-6c61647456a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset(\"json\", data_files=\"./data/qa_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5454b818-0242-4171-83a3-f42aa812e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/warreconn_data_cn_ordering.csv\")\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62ed5de9-4312-4ea2-a056-53e463305542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '权益购买的功能用途是什么？',\n",
       " 'answer': '权益购买的功能用途是购买需要的平台版本，确定该账号所持权益，并进行付款和索取发票。这个功能可以让用户根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。同时，用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c93f7ff-aba5-46e8-8334-e965c48e6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    ": {data_point[\"question\"]}\n",
    ": {data_point[\"answer\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dd63a97-911a-4b44-a9ee-660e41d7e45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9b5c62442a49d08587437a02d6ca3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset.shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14efec96-db34-48dd-9040-b65962b4c51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f9edd-7e67-47ce-a8c9-d70a74e945ee",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75c852d8-f8da-4741-8b1a-5abbdc8a8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d52eef9-e6f4-43bc-b26c-eb0f718c303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd070530fe26a16b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd070530fe26a16b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiments/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c937bb14-2b85-411b-a6c7-b1c58bb113d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=80,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76d9169c-3e9f-40ee-ac07-74e90aed3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6aef64a-6e10-41cb-8d6f-1c6d85c2b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 03:23, Epoch 64/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.613500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.696300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 5s, sys: 20 s, total: 3min 25s\n",
      "Wall time: 3min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.11792703644605354, metrics={'train_runtime': 205.7477, 'train_samples_per_second': 1.555, 'train_steps_per_second': 0.389, 'total_flos': 2054819736453120.0, 'train_loss': 0.11792703644605354, 'epoch': 64.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f96d2-f805-4650-a4fe-ea92fcbc765f",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6901fecc-e580-4b26-99dc-87e228699bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"llama2_cn_trained-model_ordering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac960481-cdf7-49a9-845e-3e1ba47e57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80813bf8-ff27-4f5d-87eb-b610e56c1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_model_name = \"llama2_cn_trained-model\"\n",
    "# model.push_to_hub(peft_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2a1d3-4296-42f4-9e96-88dadfa98bc3",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "667641a3-b332-4b46-80dd-24fe40b2edb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae70f087b18a4f98979964e9275b584c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# PEFT_MODEL = f\"ysw96/{peft_model_name}\"\n",
    "PEFT_MODEL = f\"./llama2_cn_trained-model_ordering\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    # trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d406a-2858-41c0-b05a-9d5056a2667e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27d48dfd-b351-4885-a085-00fe6380e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.0\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5053d12d-f7ed-4514-a75c-8f8b89c2aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23f4a9e7-8863-4051-aae1-aefffa67764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 权益购买的功能用途是什么？\n",
      ": 权益购买的功能用途是购买需要的平台版本，确定该账号所持权益，并进行付款和索取发票。这个功能可以让用户根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。同时，用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。\n",
      "\n",
      "CPU times: user 15.5 s, sys: 58.5 ms, total: 15.6 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = f\"\"\"\n",
    ": 权益购买的功能用途是什么？\n",
    ":\n",
    "\"\"\".strip()\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73c22282-5754-457f-994b-013876bc455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    ": {question}\n",
    ":\n",
    "\"\"\".strip()\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=encoding.input_ids,\n",
    "            attention_mask=encoding.attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_start = \":\"\n",
    "    response_start = response.find(assistant_start)\n",
    "    return response[response_start + len(assistant_start) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23e91a9c-9324-4b34-8cb6-b79f63d9c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权益购买的功能用途是什么？\n",
      ": 权益购买的功能用途是购买需要的平台版本，确定该账号所持权益，并进行付款和索取发票。这个功能可以让用户根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。同时，用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"权益购买的功能用途是什么？\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a708b426-20db-4821-82da-d05efb25026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权益购买的具体操作步骤是什么？\n",
      ": 权益购买的具体操作步骤包括登录账号后，点击【平台版本】，进入权益购买界面，【+选择权益】可进行预购版本的选择，点击下一步或者购物车，进行订单的确认和提交。订单提交后重新登录。这些步骤可以让用户方便地选择需要的平台版本，并完成订单的提交。同时，用户可以在订单提交时进行付款\n"
     ]
    }
   ],
   "source": [
    "prompt = \"权益购买的具体操作步骤是什么？\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d15b9c33-44e4-47c4-8421-7910d5a62293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如何选择需要的平台版本？\n",
      ": 在权益购买界面，用户可以进行预购版本的选择，点击【+选择权益】即可。用户可以根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。以下是一些可能的选择方案：\n",
      "\n",
      "1. 权益购买的基本版本，用户可以选择这个版本，方便管理自己的平台账号和权益。这个版本提供的功能包括购买\n",
      "CPU times: user 17.9 s, sys: 40.3 ms, total: 18 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"如何选择需要的平台版本？\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0de3c9bf-f2a2-4a4f-954e-4e18850d3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如何确认订单并进行提交？\n",
      ": 在权益购买界面，用户可以点击下一步或者购物车，进行订单的确认和提交。用户需要仔细核对订单信息，确保订单信息无误后再进行提交。提交订单后，用户需要重新登录账号。用户需要仔细权益购买界面，确保订单信息无误后再进行提交。提交订单后，用户需要重新登录账号。用户需要仔细权益购买界\n",
      "CPU times: user 18.1 s, sys: 32.5 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"如何确认订单并进行提交？\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88305826-93d5-437a-b157-12929fe1e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否可以索取发票？\n",
      ": 是的，权益购买功能可以进行付款和索取发票。用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。用户需要填写发票抬头、类型、寄送地址等发票信息，并确认发。用户可以选择需要的发票类型，包括平台版本、平台版本的免费版本、付款和索取发票。用户需要填写发票抬头、类型、寄送\n",
      "CPU times: user 18.1 s, sys: 48 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"是否可以索取发票？\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59625ec-a921-46e4-a1cb-ce79951590c0",
   "metadata": {},
   "source": [
    "## Similar question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75dd0228-0a4b-4683-9d32-73c50373897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一定要购买权益吗?\n",
      ": 是的，权益购买功能可以进行付款和索取发票。用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。用户需要填写发票抬头、类型、寄送地址等发票信息，并确认发。用户可以根据自己的需求选择不同的发票类型，以便更好地管理账务和报销。购买权益时用户需要填写发票抬头\n",
      "CPU times: user 18.3 s, sys: 46.6 ms, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"一定要购买权益吗?\"\n",
    "print(generate_response(prompt)) #Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecb20660-95b2-410a-b2bc-e2168d79940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如何购买权益?\n",
      ": 在权益购买界面，用户可以进行付款和索取发票。用户需要填写发票抬头、类型、寄送地址等发票信息，并确认发。用户需要仔细核对发票信息，确保发票信息无误后再进行提交。提交发票后，用户需要重新登录账号。用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。用户需要�����������\n",
      "CPU times: user 18.3 s, sys: 63.8 ms, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"如何购买权益?\"\n",
    "print(generate_response(prompt)) #Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87d48097-4359-4602-91b5-8feb47ab223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如何选择不同的平台版本?\n",
      ": 在权益购买界面，用户可以进行预购版本的选择，点击【+选择权益】即可。用户可以根据自己的需求选择不同的平台版本，以便更好地使用平台提供的服务。以下是一些可能的选择方案：\n",
      "\n",
      "1. 权益购买的具体操作步骤是什么？\n",
      "\n",
      "权益购买的具体操作步骤包括登录账号后，点击【平台版本\n",
      "CPU times: user 18.1 s, sys: 41.4 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"如何选择不同的平台版本?\"\n",
    "print(generate_response(prompt)) #Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55aa6b51-6af3-4353-8de5-77ce95ce1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单在哪里查看?\n",
      ": 订单可以在权益购买界面进行查看，用户可以点击【平台版本】，进入订单界面，【+选择权益】可进行订单的选择，订单信息可进行预购版本的选择，点击下一步或者购物车，进行订单的确认和提交。订单提交后重新登录。用户可以在订单界面进行付款和索取发票。用户需要填写发票抬头、类型、寄送地址等发票信息。用\n",
      "CPU times: user 21.4 s, sys: 40 ms, total: 21.4 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"订单在哪里查看?\"\n",
    "print(generate_response(prompt)) #Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3ef4ae4-b223-4cda-8784-90a2867261e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可以开发票吗?\n",
      ": 是的，权益购买功能可以进行付款和索取发票。用户可以在购买权益时进行付款和索取发票，方便管理账务和报销。用户需要填写发票抬头、类型、寄送地址等发票信息，并确认发。用户可以选择需要的发票类型，如平台版本发票、权益购买发票等。用户需要填写发票信息的具体操作步骤可以参�\n",
      "CPU times: user 18.1 s, sys: 35 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"可以开发票吗?\"\n",
    "print(generate_response(prompt)) #Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f1f03-2f88-44d3-9ded-7c54a46d3687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

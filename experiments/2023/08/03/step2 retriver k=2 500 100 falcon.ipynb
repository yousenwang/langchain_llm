{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc3f826-e980-4a38-a8e7-afb8b16532a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  3 14:33:38 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                        Off| 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   68C    P0               32W /  70W|      2MiB / 15360MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5158cb24-a0c3-4b90-b602-cc9255bc4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "# from InstructorEmbedding import INSTRUCTOR\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996ef127-9a25-4f67-ad56-4021a312e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                      model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74a8206-14fd-4a53-93e6-f2d85a106970",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db_500_100'\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de328c9c-488b-4417-b051-cd952b15060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46213d3a-95b4-498d-9de5-79874a633a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  3 14:34:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                        Off| 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   67C    P0               32W /  70W|      2MiB / 15360MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d4feec-feb0-412d-bbae-96e4ff952e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"How can I navigate to the RMA request page in the Wareconn Customer Portal?\"\n",
    "ans1 = retriever.get_relevant_documents(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5186481e-a59f-49a2-b519-0992fb5c04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"What does the Reminder field indicate when submitting an RMA request?\"\n",
    "ans2 = retriever.get_relevant_documents(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fbb2fb-1a67-4111-ad5d-21eee90bc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = \"What information should be filled in the Customer No. field when submitting an RMA request?\"\n",
    "ans3 = retriever.get_relevant_documents(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e271f2-623b-4736-a21c-e6cab02ea36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = \"What steps should be followed when filling in the request information for an RMA?\"\n",
    "ans4 = retriever.get_relevant_documents(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d84adc-089a-45b5-a29c-ac0bedb7faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = \"Can this document be used for purposes other than introducing Wareconn functions and procedures?\"\n",
    "ans5 = retriever.get_relevant_documents(q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00d0c70-9ef4-449b-ac8f-1372b12026fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Name: gpt4all\n",
      "Version: 1.0.8\n",
      "Summary: Python bindings for GPT4All\n",
      "Home-page: https://pypi.org/project/gpt4all/\n",
      "Author: Richard Guo\n",
      "Author-email: richard@nomic.ai\n",
      "License: \n",
      "Location: /data/python/gpt4all/gpt4all-bindings/python\n",
      "Editable project location: /data/python/gpt4all/gpt4all-bindings/python\n",
      "Requires: requests, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf94f4c-422e-45d9-950b-ea6c4436746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"ggml-model-gpt4all-falcon-q4_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd13f037-acfb-4fa3-88fb-211ff5484db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /root/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "falcon_model_load: loading model from '/root/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin' - please wait ...\n",
      "falcon_model_load: n_vocab   = 65024\n",
      "falcon_model_load: n_embd    = 4544\n",
      "falcon_model_load: n_head    = 71\n",
      "falcon_model_load: n_head_kv = 1\n",
      "falcon_model_load: n_layer   = 32\n",
      "falcon_model_load: ftype     = 2\n",
      "falcon_model_load: qntvr     = 0\n",
      "falcon_model_load: ggml ctx size = 3872.64 MB\n",
      "falcon_model_load: memory_size =    32.00 MB, n_mem = 65536\n",
      "falcon_model_load: ........................ done\n",
      "falcon_model_load: model size =  3872.59 MB / num tensors = 196\n"
     ]
    }
   ],
   "source": [
    "import gpt4all\n",
    "gptj = gpt4all.GPT4All(llm_name,allow_download=False, model_path='/root/.cache/gpt4all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78334104-3a32-41b2-be25-8e5e44192391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_name = \"ggml-model-gpt4all-falcon-q4_0.bin\"\n",
    "# falcon = gpt4all.GPT4All(llm_name,allow_download=False, model_path='/root/.cache/gpt4all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d18d1d0f-36a9-45c3-b06e-16ffce5ac15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "total 7.4G\n",
      "drwxr-xr-x  2 root root   98 2023-08-02__16:17:05 .\n",
      "drwxr-xr-x. 8 root root   91 2023-07-31__14:13:10 ..\n",
      "-rw-r--r--  1 root root 3.6G 2023-05-10__20:09:23 ggml-gpt4all-j-v1.3-groovy.bin\n",
      "-rw-r--r--  1 root root 3.8G 2023-06-28__00:32:51 ggml-model-gpt4all-falcon-q4_0.bin\n",
      "-rw-r--r--  1 root root  157 2023-08-02__16:17:05 p.py\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /root/.cache/gpt4all/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23897c37-a96e-4ca5-854f-28a0596ba1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "total 3.8G\n",
      "drwxr-xr-x 2 root root   56 2023-08-02__11:26:33 .\n",
      "drwxrwxrwx 6 root root 4.0K 2023-08-03__14:33:30 ..\n",
      "-rw-r--r-- 1 root root 3.8G 2023-08-02__15:40:08 ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f58a1dfe-7a0c-44af-8d9e-1dbc2c2b6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "050dcb5c-1dd5-4ada-af5f-ce69b2b48f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (prompt: str, max_tokens: int = 200, temp: float = 0.7, top_k: int = 40, top_p: float = 0.4, repeat_penalty: float = 1.18, repeat_last_n: int = 64, n_batch: int = 8, n_predict: Optional[int] = None, streaming: bool = False, callback: Callable[[int, str], bool] = <function empty_response_callback at 0x7f7b0133cb80>) -> Union[str, Iterable[str]]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(gptj.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf891ab-613f-4d6f-8565-d69a8ecda192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_template(context, query):\n",
    "  return  f\"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "  {context}\n",
    "\n",
    "  Question: {query}\n",
    "  Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e722db2-2ad5-4460-bd98-af1988a9be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "  1.1 RMA request  procedure (Parts return)  \n",
      "1. System login  \n",
      "⚫ Module: https://www.wareconn.com/  \n",
      "⚫ Description:  Login  with account and password  \n",
      " \n",
      "To log in, follow these steps:  \n",
      "Go to https://www.wareconn.com/ and click Log in  \n",
      " \n",
      "Fill in your email and password, then click Login\n",
      " \n",
      "Click Enter  in the Customer portal3 / 6 \n",
      "This document  belongs to Wareconn  Technology Services (Tianjin) Co., Ltd. It is only intended to be \n",
      "used to introduce Wareconn functions and procedures. Please do not use it for other purposes.  3 wareconn standard operating procedure  \n",
      "2. Go to  RMA Request  Page \n",
      "⚫ Module: Customer portal -Warranty Claims -Warranty Claims  \n",
      "⚫ Description: Go to RMA request page  \n",
      " \n",
      "To go to the RMA request page, follow these steps:  \n",
      "Click Warranty Claims  in the left menu, then click +Add\n",
      "\n",
      "  Question: How can I navigate to the RMA request page in the Wareconn Customer Portal?\n",
      "  Answer:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "content_with_ans1 = \"\"\n",
    "for i, a in enumerate(ans1):\n",
    "  content_with_ans1+=a.page_content\n",
    "\n",
    "prompt1 = generate_from_template(content_with_ans1, q1)\n",
    "print(prompt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8613429a-91e5-49c8-981b-3fa67442b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To navigate to the RMA request page in the Wareconn Customer Portal, you need to click on the Warranty Claims option in the left-hand navigation menu. Then, click on the \"+Add\" button to create a new RM\n",
      "CPU times: user 3min 39s, sys: 1.23 s, total: 3min 41s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You can run raw generate as well on your input. But performance will degrade.\n",
    "res = gptj.generate(prompt1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8a028cc-9860-45bc-9ed6-534df4ac83b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "  The Reminder field will show you whether this RMA request is approvable  \n",
      "(acceptable)  for warranty provider  or not.  \n",
      "Please remember to fill in WAL# in Customer No. field  \n",
      "Lastly, click Submit  in the top right corner to finish the  RMA requesting process6 / 6 \n",
      "This document  belongs to Wareconn  Technology Services (Tianjin) Co., Ltd. It is only intended to be \n",
      "used to introduce Wareconn functions and procedures. Please do not use it for other purposes.  6 wareconn standard operating procedure  \n",
      "5. Submit the RMA  request  \n",
      " \n",
      "⚫ Module: Customer portal -Warranty Claims -Warranty Claims -Submit  \n",
      "⚫ Description: Submit the RMA request  \n",
      " \n",
      "The Reminder field will show you whether this RMA request is approvable\n",
      "\n",
      "  Question: What does the Reminder field indicate when submitting an RMA request?\n",
      "  Answer:\n"
     ]
    }
   ],
   "source": [
    "content_with_ans2 = \"\"\n",
    "for i, a in enumerate(ans2):\n",
    "  content_with_ans2+=a.page_content\n",
    "\n",
    "prompt2 = generate_from_template(content_with_ans2, q2)\n",
    "print(prompt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe88729-22f2-4380-9c8f-944a40aedbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 152 ms, total: 2min 30s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You can run raw generate as well on your input. But performance will degrade.\n",
    "res2 = gptj.generate(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d259bde-05a0-4268-ad18-a133551e624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Remiinder field indicates whether the RMA request is approvable for warranty provider.\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a11a0c-8255-43df-ae82-c474b3208762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "  The Reminder field will show you whether this RMA request is approvable  \n",
      "(acceptable)  for warranty provider  or not.  \n",
      "Please remember to fill in WAL# in Customer No. field  \n",
      "Lastly, click Submit  in the top right corner to finish the  RMA requesting process1.1 RMA request  procedure (Parts return)  \n",
      "1. System login  \n",
      "⚫ Module: https://www.wareconn.com/  \n",
      "⚫ Description:  Login  with account and password  \n",
      " \n",
      "To log in, follow these steps:  \n",
      "Go to https://www.wareconn.com/ and click Log in  \n",
      " \n",
      "Fill in your email and password, then click Login\n",
      " \n",
      "Click Enter  in the Customer portal\n",
      "\n",
      "  Question: What information should be filled in the Customer No. field when submitting an RMA request?\n",
      "  Answer:\n"
     ]
    }
   ],
   "source": [
    "content_with_ans3 = \"\"\n",
    "for i, a in enumerate(ans3):\n",
    "  content_with_ans3+=a.page_content\n",
    "\n",
    "prompt3 = generate_from_template(content_with_ans3, q3)\n",
    "print(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b655bd8f-d982-4635-8b89-5125e8902dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Reminder field will show you whether this RMA request is approvable for warranty provider or not.\n",
      "CPU times: user 2min 17s, sys: 74.9 ms, total: 2min 17s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You can run raw generate as well on your input. But performance will degrade.\n",
    "res3 = gptj.generate(prompt3)\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4a9e74-796a-4f2c-ac55-bd77f5380913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "  The Reminder field will show you whether this RMA request is approvable  \n",
      "(acceptable)  for warranty provider  or not.  \n",
      "Please remember to fill in WAL# in Customer No. field  \n",
      "Lastly, click Submit  in the top right corner to finish the  RMA requesting process1.1 RMA request  procedure (Parts return)  \n",
      "1. System login  \n",
      "⚫ Module: https://www.wareconn.com/  \n",
      "⚫ Description:  Login  with account and password  \n",
      " \n",
      "To log in, follow these steps:  \n",
      "Go to https://www.wareconn.com/ and click Log in  \n",
      " \n",
      "Fill in your email and password, then click Login\n",
      " \n",
      "Click Enter  in the Customer portal\n",
      "\n",
      "  Question: What steps should be followed when filling in the request information for an RMA?\n",
      "  Answer:\n"
     ]
    }
   ],
   "source": [
    "content_with_ans4 = \"\"\n",
    "for i, a in enumerate(ans4):\n",
    "  content_with_ans4+=a.page_content\n",
    "\n",
    "prompt4 = generate_from_template(content_with_ans4, q4)\n",
    "print(prompt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a16ceac-4fd4-4544-8640-db03529f7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Reminder field will show whether this RMA request is approvable for warranty provider or not. Please remember to fill in WAL# in Customer No. field. Lastly, click Submit in the top right corner to finish the RMA requesting process.\n",
      "CPU times: user 2min 48s, sys: 84.9 ms, total: 2min 48s\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You can run raw generate as well on your input. But performance will degrade.\n",
    "res4 = gptj.generate(prompt4)\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65de5662-46b9-429a-9701-07343be22173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "  1 / 6 \n",
      "This document  belongs to Wareconn  Technology Services (Tianjin) Co., Ltd. It is only intended to be \n",
      "used to introduce Wareconn functions and procedures. Please do not use it for other purposes.  1 wareconn standard operating procedure  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "wareconn standard operating procedure  \n",
      "RMA request  SOP  \n",
      " \n",
      "Version : \n",
      "Version  Date  Editor  Description  \n",
      "v 1.0  2023/03/16 Eric Sun First draft (English version)  \n",
      " \n",
      " \n",
      "Content5 / 6 \n",
      "This document  belongs to Wareconn  Technology Services (Tianjin) Co., Ltd. It is only intended to be \n",
      "used to introduce Wareconn functions and procedures. Please do not use it for other purposes.  5 wareconn standard operating procedure  \n",
      "4. Fill in request info  \n",
      "⚫ Module: Customer portal -Warranty Claims -Warranty Claims -Fill in info  \n",
      "⚫ Description:  \n",
      "Fill in Product SN, Product PN and defective reason  (See the instruction s below )\n",
      "\n",
      "  Question: Can this document be used for purposes other than introducing Wareconn functions and procedures?\n",
      "  Answer:\n"
     ]
    }
   ],
   "source": [
    "content_with_ans5 = \"\"\n",
    "for i, a in enumerate(ans5):\n",
    "  content_with_ans5+=a.page_content\n",
    "\n",
    "prompt5 = generate_from_template(content_with_ans5, q5)\n",
    "print(prompt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469ede5e-7958-4f2d-8954-e1ebeba55e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, this document is only intended to be used for Wareconn functions and procedures.\n",
      "CPU times: user 3min 7s, sys: 98.7 ms, total: 3min 7s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You can run raw generate as well on your input. But performance will degrade.\n",
    "res5 = gptj.generate(prompt5)\n",
    "print(res5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241c7b3-b183-43a0-afa5-42b3f20ccc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

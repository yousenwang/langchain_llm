{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215edf84-4f08-4d3e-ac30-4e9a7900072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/llms/llm_caching\n",
    "import langchain\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.cache import RedisSemanticCache, RedisCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a67c89-119e-4533-bf99-921371a60520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: redis\n",
      "Version: 5.0.0\n",
      "Summary: Python client for Redis database and key-value store\n",
      "Home-page: https://github.com/redis/redis-py\n",
      "Author: Redis Inc.\n",
      "Author-email: oss@redis.com\n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.10/site-packages\n",
      "Requires: async-timeout\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab21c64d-67da-4579-b6d3-db48b078afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "os.environ['HTTP_PROXY']=\"http://127.0.0.1:8098\"\n",
    "os.environ['HTTPS_PROXY']=\"http://127.0.0.1:8098\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529224e6-9048-4a95-89e7-1894c3f6dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Obtaining dependency information for redis from https://files.pythonhosted.org/packages/df/b2/dfdc17f701f7b587f6c89c2b9b6b5978c87a8a785555efc810b064c875de/redis-5.0.0-py3-none-any.whl.metadata\n",
      "  Downloading redis-5.0.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/site-packages (from redis) (4.0.2)\n",
      "Downloading redis-5.0.0-py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m735.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-5.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152f8375-2503-4f36-a231-07c25a81d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis\n",
    "r = Redis(\n",
    "    host=\"localhost\",\n",
    "    port=6379,\n",
    "    password=\"Wareconn123\",\n",
    "    decode_responses=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90e4110-11a8-4943-9517-d94948691a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "langchain.llm_cache = RedisCache(\n",
    "    redis_=r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8d4d4c-129a-4063-85c7-79318c52e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 15:50:32.038540: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 15:50:32.898145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                      model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28fee616-e68f-4ee2-a373-bfba5d7b12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = RedisSemanticCache(\n",
    "    # redis_url=\"redis://ethan:Wareconn123@127.0.0.1:6379/0\",\n",
    "    redis_url=\"redis://default:Wareconn123@localhost:6379/0\",\n",
    "    # redis_url=\"redis://localhost:6379\",\n",
    "    embedding=instructor_embeddings,\n",
    "    score_threshold=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4a5f0b-6572-48e9-aa06-bcc546115824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 24 15:50:52 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   66C    P8              13W /  70W |      5MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157d3de-44e4-4715-af26-ac5dc0925d8d",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13abcb1-eb81-44d4-8c99-6b57e033f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d43353e-b9c8-493f-91a2-0fcd71ae505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name,\n",
    "                                          local_files_only=True\n",
    "                                          # use_auth_token=True,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069bfdd7-fdd8-448d-9a09-d6001760169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:31:51.917915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 16:31:52.749753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41533abe573c4cebae5a83bc150a0ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             local_files_only=True,\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             temperature=0\n",
    "                                             # use_auth_token=True,\n",
    "                                            #  load_in_8bit=True,\n",
    "                                            #  load_in_4bit=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f80317-032b-43b9-9b2c-9653e4155e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 24 16:32:03 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   68C    P0              32W /  70W |  13095MiB / 15360MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    107444      C   /usr/local/bin/python3.10                 13090MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ccb1e4-612d-497f-aa2e-18b45a42f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe81c9-9010-4cd8-a52b-1022e830a50f",
   "metadata": {},
   "source": [
    "https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_pipeline.HuggingFacePipeline.html#langchain.llms.huggingface_pipeline.HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e041c2b-aada-4d99-b0a8-9dc73e625934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac18ea8-1f24-49e7-bbac-1e61196b3e87",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a139818-3e0d-4a33-85be-7fc4c5f62cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.cache.RedisCache at 0x7fb5ac439840>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "537a34f1-d375-475a-a50f-e85ef6bc1170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tutorials', 'b375f98a87425857302ab34e14743a65']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bba5a3d-ab68-463f-b4c1-9d8a1cde47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e0a046-c392-4210-adc5-45cb4116ccbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dd8f750-25ec-47e1-a6bc-83bd322c966c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RedisCache' object has no attribute '_cache_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlangchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_dict\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RedisCache' object has no attribute '_cache_dict'"
     ]
    }
   ],
   "source": [
    "langchain.llm_cache._cache_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b453d-8bb8-4da2-8e66-5b1419e36a8a",
   "metadata": {},
   "source": [
    "# Runtime improve after caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9cc8a41-b2c7-4521-8963-8d24370fa528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.29 s, sys: 1.37 s, total: 6.65 s\n",
      "Wall time: 6.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' you want to use.\\n\\nAnswer: Sure! Here are three colors you can use for your color scheme:\\n\\n1. Navy blue (#032B44)\\n2. Light gray (#F7F7F7)\\n3. Bright green (#34C759)\\n\\nThese colors have a nice contrast and can work well together. You can use navy blue as the primary color and light gray and bright green as accent colors.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(\"name 3 colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf14175b-8cee-4c02-8e6f-d9768ada64ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 ms, sys: 404 µs, total: 2.19 ms\n",
      "Wall time: 1.75 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' you want to use.\\n\\nAnswer: Sure! Here are three colors you can use for your color scheme:\\n\\n1. Navy blue (#032B44)\\n2. Light gray (#F7F7F7)\\n3. Bright green (#34C759)\\n\\nThese colors have a nice contrast and can work well together. You can use navy blue as the primary color and light gray and bright green as accent colors.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(\"name 3 colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7955d9b1-df48-4edf-869b-3d24501fc2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.cache.RedisCache at 0x7ff0a82da980>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45c5ac82-1cee-4e6f-b6a0-74161c8a214f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RedisCache' object has no attribute '_cache_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlangchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_dict\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RedisCache' object has no attribute '_cache_dict'"
     ]
    }
   ],
   "source": [
    "langchain.llm_cache._cache_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2745ee9-7fb6-49e2-9a41-25287c48c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b375f98a87425857302ab34e14743a65']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "133bec9b-7a5a-4229-9c80-62545ca66d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.lookup(\"name 3 colors\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65735d79-54cd-4270-bf23-3f6498f425ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045408c9-9fc1-45af-b2d9-e73963fc7c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

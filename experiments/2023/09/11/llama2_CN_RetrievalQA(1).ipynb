{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63ea281-382b-4472-9029-b18bc87d0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 11 16:18:57 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     Off | 00000000:AF:00.0 Off |                    0 |\n",
      "|  0%   32C    P0              69W / 300W |   6248MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    120125      C   python                                      978MiB |\n",
      "|    0   N/A  N/A    135052      C   ./server                                   5250MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2da1071-7fdb-4bf2-87d1-db5b49c1d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lah /root/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a81b140-273b-4b8b-9ed5-e01d7f390ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.5G\n",
      "drwxr-xr-x 2 root root  237 Aug 31 10:56 .\n",
      "drwxr-xr-x 4 root root   76 Aug 31 10:56 ..\n",
      "-rw-r--r-- 1 root root 1.5K Aug 31 09:35 .gitattributes\n",
      "-rw-r--r-- 1 root root  443 Aug 31 09:35 README.md\n",
      "-rw-r--r-- 1 root root  821 Aug 31 09:35 config.json\n",
      "-rw-r--r-- 1 root root   69 Aug 31 09:35 eval_results.txt\n",
      "-rw-r--r-- 1 root root 1.3G Aug 31 10:15 model.safetensors\n",
      "-rw-r--r-- 1 root root 1.3G Aug 31 10:56 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root  125 Aug 31 10:56 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 430K Aug 31 10:56 tokenizer.json\n",
      "-rw-r--r-- 1 root root  514 Aug 31 10:56 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 107K Aug 31 10:56 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e2fd7b-2f9d-498c-a533-876650b4c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys,os,os.path\n",
    "# os.environ['HTTP_PROXY']=\"http://127.0.0.1:8098\"\n",
    "# os.environ['HTTPS_PROXY']=\"http://127.0.0.1:8098\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e3a37f-2b9a-4b3e-a021-fd5aecb8ca45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b409b4-8678-4222-9312-1a753c4a06a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247f003d-a643-454f-9b84-6d98025ca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/bigscience/bloom-1b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f708942-cb93-4534-ba9b-889ea5685b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91acc2a1-551f-407b-8c3a-79bb724920fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BloomTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ac1af5-f5dd-48fe-8bd0-155c443d2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BloomTokenizerFast.from_pretrained(\n",
    "#     \"bigscience/bloom-1b7\",\n",
    "#     local_files_only=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "276ddb1a-e6d3-440f-b223-4956cefb033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FlagAlpha/Llama2-Chinese-7b-Chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0522d3-b385-44a5-9a1a-aea93dede9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name,\n",
    "                                          local_files_only=True\n",
    "                                          # use_auth_token=True,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46010d89-3940-45dc-8af3-0653d29b91bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8dd1ec4-5f36-4159-a9de-45c4a5a9107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ed3a17-9585-4091-ab66-378f7d3c8ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 16:19:00.912072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 16:19:01.606064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b337d774377446a8ba281070b7306f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             local_files_only=True,\n",
    "                                             device_map='auto',\n",
    "                                             # torch_dtype=torch.float16,\n",
    "                                             temperature=0.2, # must be strictly positive float\n",
    "                                             do_sample=True,\n",
    "                                             # use_auth_token=True,\n",
    "                                            #  load_in_8bit=True,\n",
    "                                            #  load_in_4bit=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2451c65-8ceb-4014-bb47-e452e6221d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 11 16:19:16 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     Off | 00000000:AF:00.0 Off |                    0 |\n",
      "|  0%   32C    P0              71W / 300W |  32459MiB / 46068MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    120125      C   python                                      978MiB |\n",
      "|    0   N/A  N/A    135052      C   ./server                                   5250MiB |\n",
      "|    0   N/A  N/A    135331      C   /usr/local/bin/python3.10                 26206MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9ee30c-667c-4016-8493-947d8305e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/shibing624/text2vec/issues/116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af393595-fda2-4673-a91b-48d51292063e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.cache/torch'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.hub import _get_torch_home\n",
    "\n",
    "_get_torch_home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450732c9-883a-4480-bdff-2029694cc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"/root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese\",\n",
    "                                                      # local_files_only=True,\n",
    "                                                      model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "098c1da5-271d-439c-8fc2-9b2aa11faeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceInstructEmbeddings(client=INSTRUCTOR(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "), model_name='/root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese', cache_folder=None, model_kwargs={'device': 'cuda'}, encode_kwargs={}, embed_instruction='Represent the document for retrieval: ', query_instruction='Represent the question for retrieving supporting documents: ')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdfc55f-2b9c-48b7-b83c-1fdaa146f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 11 16:19:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     Off | 00000000:AF:00.0 Off |                    0 |\n",
      "|  0%   32C    P0              69W / 300W |  32459MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    120125      C   python                                      978MiB |\n",
      "|    0   N/A  N/A    135052      C   ./server                                   5250MiB |\n",
      "|    0   N/A  N/A    135331      C   /usr/local/bin/python3.10                 26206MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df92eabf-bfaa-46a4-9755-5c2715900a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'db_cn'\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=instructor_embeddings)\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19284d11-d70e-48d0-985a-7e9200c9e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"在哪里可以设定机种?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08ab26e-54b2-4556-8b09-8061be276ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_k = vectordb.as_retriever(\n",
    "    search_kwargs={'k': 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8df9955-286f-4083-a418-52c8b79a90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2 = retriever_k.get_relevant_documents(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4f45684-f885-4b50-a13b-cacc026a9bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccd19374-32fe-4343-9c67-23da29a74ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='选择是否设定附加规则 , 限制 SN长度或厂家代码范围等 , 设定完毕后 , 点击【保存】 , \\n完成该产品序列号判定逻辑设定 .', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 7}),\n",
       " Document(page_content='选定不良代码 , 点击进入客户绑定页面 ; 勾选客户 , 点击【保存】完成不良判定代码\\n与客户的绑定 ; \\n \\n \\n保修设定  \\n1. 定义产品 (整机料号信息 ) \\n单笔或批量将产品信息导入系统 ,包含机种、厂家料号、客户料号、供应商料号、替代\\n料号等信息  \\n1.1 机种管理  \\n若产品涉及机种 , 需先将机种信息新增至系统 , 以便后续选择 . \\na. 单笔新增机种  \\n厂家保修管理 后台 ->保修设定 ->定义产品 , 点击【机种管理】按钮 , 点击【新增】填写\\n机种名称 , 点击【保存】完成 ;', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 10}),\n",
       " Document(page_content='1.9 产品与附件绑定  \\n本操作步骤 , 需要在本章 2. 定义附件  操作完成后进行 . \\n厂家保修管理 后台 ->保修设定 ->定义产品 , 选定产品 , 点击按钮 , 点击【绑定附件】并勾\\n选对应附 件、填写数量 , 点击【绑定】完成 ; \\n \\n \\n2. 定义部件 （备品料号信息）  \\n若部件中涉及机种管理 , 亦需先新增或上传机种 , 而后操作步骤同定义产品  \\n2.1 新增部件机种  \\n点击【机种管理】按钮 , 点击【新增】单笔新增机种 ; 点击【上传机种】下载模板 , 批\\n量新增机种 ;  \\n2.2 新增部件  \\n点击【新增部件】单笔新增部件 ; 点击【上传部件】下拉框 , 下载模板批量新增部件 ; \\n2.3 新增部件客户料号 ; \\n点击【料号对照】添加客户料号 , 选定产品 , 点击单笔添加 ; 点击【料号对照】下载模\\n板, 批量上传料号 ; \\n2.3 新增供应商料号  \\n点击【供应商料号】 , 选定产品 , 点击按钮 , 点击【添加供应商】 , 添加供应商及供应\\n商料号 , 【保存】完成 .', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 16})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb29db35-5da5-409e-83c7-2c7a33b2e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae221f91-788e-4f8b-921a-1ec3ed6ede7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/modules/model_io/models/chat/prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f80a44e-39e3-4afb-b545-19f840cd9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                # return_full_text=True,\n",
    "                # torch_dtype=torch.bfloat16,\n",
    "                # device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "331cfdb4-eb08-4db9-838b-c1ec3133583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39176f3e-a8e3-4034-b32f-ca9d00e63f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nЋ：你好，我是来自中国的学生。\\nA：很高兴认识你，我是来自美国的学生。你在这里学习了哪些科目？\\nЋ：我学习了数学、物理和化学。你在这里学习了什么科目？\\nA：我学习了历史、政治和经济学。你认为这些科目对你的未来有哪些帮助？\\nЋ：我认为这些科目对我的未来有很大的帮助，因为它们可以帮助我更好地理解世界和人类的行为。\\nA：我也认为这些科目对我的未来有很大的帮助，因为它们可以帮助我更好地理解世界和人类的行为。\\nЋ：我们有很多共同的兴趣，我们可以一起参加一些学术活动。\\nA：我也非常感谢你的提议，我们可以一起参加一些学术活动。\\n\\n\\n基于以上这段对话内容回答：\\n这两个学生之间有什么共同点吗？\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"你好嗎?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94548df9-82b9-4bd6-af3e-c56e8c6c2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62b71aca-b2d6-4dc6-b3fd-612f464bcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea2d8e77-ae07-4df5-87e8-386988914d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。\n",
    "\n",
    "  {context}\n",
    "\n",
    "  问题: {queston}\n",
    "  答案:\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\n",
    "    \"prompt\": prompt_template\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21d9535f-0960-4668-af1a-1b8b981c7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。\n",
    "\n",
    "  {context}\n",
    "\n",
    "  问题: {question}\n",
    "  Answer in English:\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\n",
    "    \"prompt\": prompt_template\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fed29715-91f1-4b2f-a8bd-33e5a8cd6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 return_source_documents=True,\n",
    "                                 chain_type_kwargs=chain_type_kwargs\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fe6c587-a3b5-4f1f-a447-470fb8610d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90cecf-cfc9-4593-b8b2-a3cd31cf584b",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e926e68-d4d7-457e-8517-ab911bdb72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"如何设定判定逻辑?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0646911-545a-45eb-b7e5-d3d9db2bf9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 3.12 s, total: 15.6 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res1 = qa({\"query\": question1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "907dba52-ff5c-452e-be3e-3aa2a41c1ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '如何设定判定逻辑?',\n",
       " 'result': ' \\n\\nTo set the judgment logic, you can follow these steps:\\n\\n1. Go to the \"Basic Settings\" page in the \"Firmware Management\" system.\\n2. Click on the \"Add/Edit Judgment Logic\" button.\\n3. Select the \"PPID/SN\" judgment rule.\\n4. Fill in the judgment rule name, description, and SN sample.\\n5. Click on the \"Edit\" button to apply the changes.\\n6. Fill in the decode rule name, description, and SN sample.\\n7. Click on the \"Add\" button to add the judgment rule.\\n8. Fill in the PPID/SN sub-string section, based on the meaning of the sub-string.\\n9. Click on the \"Edit\" button to edit the judgment rule.\\n10. Fill in the monthly rule for the PPID/SN sub-string section.\\n11. Click on the \"Add a new item\" button to add a new rule.\\n12. Fill in the PPID/SN sub-string rule.\\n\\nNote: The above steps are based on the Chinese version of the instruction manual. Please refer to the English version for the exact steps.',\n",
       " 'source_documents': [Document(page_content='选择是否设定附加规则 , 限制 SN长度或厂家代码范围等 , 设定完毕后 , 点击【保存】 , \\n完成该产品序列号判定逻辑设定 .', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 7}),\n",
       "  Document(page_content='2.2 检验逻辑设定   \\n逻辑判定设置完成后 , 厂家保修管理 后台->基础设定 ->判定逻辑 , 点击进入逻辑判定\\n页面, 最下方输入 PPID, 点击【解析】检验逻辑设定 ;如下图, 可依规则自动解析出厂\\n时间等信息 . \\n \\n3. 保修类别  \\n厂家保修管理 后台->基础设定 ->保修类别，点击【新增设定】 , 设定需要为产品配置\\n的保修类别 ,填写服务类型、时效值及单位 , 点击【保存】完成 ; \\n \\n \\n4. 保修约定  \\n当产品保修及保修卡无法满足保修需求时 , 可添加保修约定 .', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 8}),\n",
       "  Document(page_content='基础设定  \\n1. 判定命名  \\n厂家保修管理 后台->基础设定 ->判定命名 ,依用户习惯 , 自主设定相关栏位名称 , 设定\\n后, 系统相关栏位均以设定名称显示 . \\n \\n2. 判定逻辑  \\n设定PPID/SN的逻辑规则 , 用于解析保修起点日期等信息 . \\n2.1 添加/编辑判定逻辑  \\n厂家保修管理 后台->基础设定 ->判定逻辑 , 点击【添加】按钮 , 添加判定逻辑 ;选定判\\n定逻辑, 点击对该判定逻辑进行编辑 ; \\n \\n填写解码规则名称、说明、 SN样例；点击【编辑】按钮 进行应用 ; \\n \\n填写 PPID/SN子串区段 , 依照子串区段 的代表意义 , 可自定义规则  \\n如下图中点击【月份 规则自定义】 ，  进入自定义模块后 , 点击【新增码值】 , 可自定义\\n月份解析规则 , 例如 , 可依 PPID/SN规则设定 A代表 10月, B代表 11月份 , C代表 12月\\n份; \\n【添加一项自定义规则】可添加 PPID/SN子串逻辑自定义规则 .', metadata={'source': 'chinese_pdf/保修管理-廠家sop-repair(去圖標).pdf', 'page': 6})]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d094e29-2a78-4d77-96bb-92d297935496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nTo set the judgment logic, you can follow these steps:\\n\\n1. Go to the \"Basic Settings\" page in the \"Firmware Management\" system.\\n2. Click on the \"Add/Edit Judgment Logic\" button.\\n3. Select the \"PPID/SN\" judgment rule.\\n4. Fill in the judgment rule name, description, and SN sample.\\n5. Click on the \"Edit\" button to apply the changes.\\n6. Fill in the decode rule name, description, and SN sample.\\n7. Click on the \"Add\" button to add the judgment rule.\\n8. Fill in the PPID/SN sub-string section, based on the meaning of the sub-string.\\n9. Click on the \"Edit\" button to edit the judgment rule.\\n10. Fill in the monthly rule for the PPID/SN sub-string section.\\n11. Click on the \"Add a new item\" button to add a new rule.\\n12. Fill in the PPID/SN sub-string rule.\\n\\nNote: The above steps are based on the Chinese version of the instruction manual. Please refer to the English version for the exact steps.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019c898-3fa5-4dd1-9656-e726bd1e70b9",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c53381b-d74b-4d52-b237-c1570da519f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"在哪里可以设定机种?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6a19c8f-35bf-4372-900c-cbf9bd3886f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 s, sys: 975 ms, total: 3.84 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res2 = qa({\"query\": question2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df16d3ce-1217-4235-9934-4fff01bb8371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 在厂家保修管理 后台 -> 保修设定 -> 定义产品 操作中，可以在 1.1 机种管理 操作中设定机种。\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87cd5a6d-19dd-4bac-a5a6-3cde355e0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"平台可以自动核准保修申请吗?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bbe1cfe6-074a-4aaf-8e9f-82cacacdcf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 s, sys: 1.15 s, total: 4.88 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "re3 = qa({\"query\": question3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b432b1c0-70ed-44a8-8a46-202236af9f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 如果客户已经设置了自动核准功能，平台可以自动核准保修申请。如果客户未设置自动核准，则需要手动核准。\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re3[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f442d52-fe72-4cd8-b87c-33feb22a49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "question4 = \"自动核准后还需要进行单号提交吗?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a61663b0-1c3d-43b4-a192-8fa91ab33a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.54 s, sys: 575 ms, total: 2.12 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res4 = qa({\"query\": question4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9e10fcd-e060-4e94-8167-30aded570c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 自动核准后，需要进行单号提交。\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68fbdc87-6419-4b4a-9357-51a85df036c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question5 = \"怎么查看保修进度?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "654ab8fe-365b-45c1-87fa-1ee23ee28daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 826 ms, total: 3.27 s\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res5 = qa({\"query\": question5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63ff0363-3603-40ba-8472-9b086287beb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 在厂家保修管理后台中，可以通过查看保修单号进入送修信息，查看保修及物流进度。\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res5[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c995f7d-f9aa-4801-a289-5975d67b00bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d459b057-571b-4042-b1df-9dc5890c90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72296f2-627a-4d72-81b7-16dd64f2029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# import nltk\n",
    "# import sklearn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    user_input:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c646f81-59a2-47e0-afbf-9041c0a8c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/\")\n",
    "async def answer_endpoint(input_q: Question):\n",
    "    question = input_q.dict()\n",
    " \n",
    "\n",
    "    return {\n",
    "        \"user_input\": question[\"user_input\"],\n",
    "    }\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"this is get\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1fdd86-603c-4972-b70e-ec75543d210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# import sklearn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    user_input:str\n",
    "    k: Optional[int] = Field(default=3)\n",
    "\n",
    "\n",
    "@app.post(\"/\")\n",
    "async def retrieve_docs(input_q: Question):\n",
    "    question = input_q.dict()\n",
    "    # numerical = str_to_numerical.transform([question[\"user_input\"]]).toarray()\n",
    "    # distance, idx = info_retrieve.query(numerical, k=1)\n",
    "\n",
    "    # best_answer = list(enumerate(idx[0]))[0]\n",
    "    instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"/root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese\",\n",
    "                                                      # local_files_only=True,\n",
    "                                                      model_kwargs={\"device\": \"cuda\"})\n",
    "    persist_directory = 'db_cn'\n",
    "\n",
    "    vectordb = Chroma(persist_directory=persist_directory,\n",
    "                      embedding_function=instructor_embeddings)\n",
    "\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": question['k']})\n",
    "\n",
    "    ans = retriever.get_relevant_documents(question[\"user_input\"])\n",
    "    docs = list(map(lambda a: {\n",
    "            'page_content': a.page_content,\n",
    "            'source': a.metadata[\"source\"],\n",
    "            'page': a.metadata[\"page\"]}, ans))\n",
    "    return {\n",
    "        \"user_input\": question[\"user_input\"],\n",
    "        \"relavant_docs\": docs\n",
    "    }\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"this is get\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974cca8f-e323-48ec-bfcc-28d91e869c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# Allow for asyncio to work within the Jupyter notebook cell\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4136a0f-7ed0-4364-8cf9-fe81187c495b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [5903]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "/usr/local/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n",
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n",
      "2023-09-05 14:33:26.249469: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 14:33:27.040586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49452 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49454 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49456 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [5903]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "uvicorn.run(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b47264-3f00-4896-a1ef-c9840753cedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0da2d9-884e-4bb2-be12-9c8e4d67f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"user_input\":\"What is the work station?\"}'\n",
      "b'{\"message\":\"this is get\"}'\n"
     ]
    }
   ],
   "source": [
    "%run use_endpoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5d918-c25b-4116-a3a0-9c525065ccde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
